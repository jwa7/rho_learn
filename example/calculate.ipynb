{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists, join\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from rhocalc.aims import aims_calc, aims_fields, aims_parser\n",
    "from rholearn import utils\n",
    "\n",
    "import chemiscope\n",
    "from dft_settings import *\n",
    "\n",
    "chemiscope.show(STRUCTURE, mode=\"structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rholearn import io\n",
    "import pandas as pd\n",
    "from settings import ALL_IDXS, ALL_STRUCTURES\n",
    "\n",
    "# Parse some calculation metrics from aims output files into a dataframe\n",
    "metric_names = [\n",
    "    \"curr_experiment\",\n",
    "    \"category\",\n",
    "    # \"geometry_from\",\n",
    "    \"size\",\n",
    "    \"z_depth_max\",\n",
    "    \"num_atoms\",\n",
    "    \"supercell\",\n",
    "    # \"num_abfs\",\n",
    "    # \"df_error_percent\",\n",
    "    # \"ri_coeffs_size_mb\",\n",
    "    # \"ri_ovlp_size_mb\",\n",
    "    # \"lsoap_size_mb\",\n",
    "    # \"linalg_loss\",\n",
    "    # \"can_overfit\",\n",
    "    # \"MAE(ML v RI) %\",\n",
    "]\n",
    "metrics = []\n",
    "for A, frame in zip(ALL_IDXS, ALL_STRUCTURES):\n",
    "    struct_row =  [\n",
    "        \"*\" if A in STRUCTURE_ID else \"\",\n",
    "        frame.info[\"category\"],\n",
    "        # frame.info[\"geometry_from\"],\n",
    "        frame.info[\"size\"],\n",
    "        np.abs(np.min(frame.positions[:, 2]) - np.max(frame.positions[:, 2])),\n",
    "        frame.get_global_number_of_atoms(),\n",
    "        frame.info.get(\"supercell\"),\n",
    "    ]\n",
    "    # if A in STRUCTURE_ID:\n",
    "    #     calc_info = io.unpickle_dict(join(PROCESSED_DIR(A), \"calc_info.pickle\"))\n",
    "    #     struct_row += [\n",
    "    # #         calc_info[\"num_abfs\"],\n",
    "    #         calc_info[\"df_error_percent\"][\"total\"],\n",
    "    # #         os.path.getsize(join(PROCESSED_DIR(A), \"ri_coeffs.npz\")) * 1e-6,\n",
    "    # #         os.path.getsize(join(PROCESSED_DIR(A), \"ri_ovlp.npz\")) * 1e-6,\n",
    "    # #         # os.path.getsize(join(PROCESSED_DIR(A), \"lsoap.npz\")) * 1e-6,\n",
    "    # #         # linalg_losses[A].detach().numpy(),\n",
    "    # #         # \"NO!\" if linalg_losses[A].detach().numpy() > 1e-10 else \"\",\n",
    "    #     ]\n",
    "\n",
    "    #     if A in [0, 1, 2, 3]:\n",
    "    #         struct_row += [\n",
    "    #             np.load(\n",
    "    #                 f\"/home/abbott/march-24/si_dimers_extrapolate/ml/ildos+1V/{A}/evaluation/epoch_eval/{A}/mae_percent.npy\"\n",
    "    #             )\n",
    "    #         ]\n",
    "    #     elif A in [16, 17, 18, 19]:\n",
    "    #         struct_row += [\n",
    "    #             np.load(\n",
    "    #                 f\"/home/abbott/march-24/si_dimers_extrapolate/ml/ildos+1V/{A - 16}/evaluation/epoch_eval/{A}/mae_percent.npy\"\n",
    "    #             )\n",
    "    #         ]\n",
    "    # else:\n",
    "    #     struct_row += [\"\"] * 5\n",
    "    metrics.append(struct_row)\n",
    "\n",
    "metrics = pd.DataFrame(metrics, columns=metric_names, index=ALL_IDXS)\n",
    "# display(metrics)\n",
    "display(metrics.iloc[STRUCTURE_ID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geom = True  # False to use optimized geometry instead\n",
    "\n",
    "# And the general settings for all calcs\n",
    "aims_kwargs = BASE_AIMS_KWARGS.copy()\n",
    "aims_kwargs.update(SCF_KWARGS)\n",
    "\n",
    "# Define paths to the aims.out files for RI calcs\n",
    "all_aims_outs = [join(SCF_DIR(A), \"aims.out\") for A in STRUCTURE_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcs = {\n",
    "#     A: {\"atoms\": structure, \"run_dir\": SCF_DIR(A)}\n",
    "#     for A, structure in zip(STRUCTURE_ID, STRUCTURE)\n",
    "# }\n",
    "calcs = {A: {\"atoms\": structure} for A, structure in zip(STRUCTURE_ID, STRUCTURE)}\n",
    "\n",
    "for aims_out in all_aims_outs:\n",
    "    if exists(aims_out):\n",
    "        shutil.copy(aims_out, aims_out + \".previous\")\n",
    "        os.remove(aims_out)\n",
    "for A in STRUCTURE_ID:\n",
    "    if exists(join(SCF_DIR(A), \"geometry.in.next_step\")):\n",
    "        shutil.copy(\n",
    "            join(SCF_DIR(A), \"geometry.in\"),\n",
    "            join(SCF_DIR(A), \"geometry.in.previous\"),\n",
    "        )\n",
    "        shutil.copy(\n",
    "            join(SCF_DIR(A), \"geometry.in.next_step\"),\n",
    "            join(SCF_DIR(A), \"geometry.in\"),\n",
    "        )\n",
    "\n",
    "    # Define cube settings for Hartree Potential\n",
    "    com = ALL_STRUCTURES[A].get_center_of_mass()\n",
    "    calcs[A][\"aims_kwargs\"] = {\n",
    "        \"cubes\": (\n",
    "            f\"cube origin {com[0]} {com[1]} {com[2]} \\n\"\n",
    "            f\"cube edge 100 0.1 0.0 0.0 \\n\"\n",
    "            f\"cube edge 100 0.0 0.1 0.0 \\n\"\n",
    "            f\"cube edge 100 0.0 0.0 0.1 \\n\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "# Run the SCF in AIMS\n",
    "aims_calc.run_aims_array(\n",
    "    calcs=calcs,\n",
    "    aims_path=AIMS_PATH,\n",
    "    aims_kwargs=aims_kwargs,\n",
    "    sbatch_kwargs=SBATCH_KWARGS,\n",
    "    run_dir=SCF_DIR,\n",
    "    load_modules=HPC_KWARGS[\"load_modules\"],\n",
    "    export_vars=HPC_KWARGS[\"export_vars\"],\n",
    "    run_command=\"srun\",\n",
    "    write_geom=write_geom,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until all AIMS calcs have finished\n",
    "all_finished = False\n",
    "while len(all_aims_outs) > 0:\n",
    "    for aims_out in all_aims_outs:\n",
    "        if exists(aims_out):\n",
    "            with open(aims_out, \"r\") as f:\n",
    "                # Basic check to see if AIMS calc has finished\n",
    "                if \"Leaving FHI-aims.\" in f.read():\n",
    "                    all_aims_outs.remove(aims_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converged = []\n",
    "for A, frame in zip(STRUCTURE_ID, STRUCTURE):\n",
    "    # Parse the calculation info\n",
    "    calc_info = aims_parser.parse_aims_out(SCF_DIR(A))\n",
    "    converged.append(calc_info[\"scf\"][\"converged\"])\n",
    "\n",
    "    # Get the Fermi energy as the VBM\n",
    "    kso_info = aims_parser.get_ks_orbital_info(join(SCF_DIR(A), \"ks_orbital_info.out\"))\n",
    "    homo_idx = aims_fields.get_homo_kso_idx(kso_info)\n",
    "    fermi_vbm = kso_info[homo_idx - 1][\"energy_eV\"]  # 1-indexing\n",
    "\n",
    "    # Calculate the Fermi energy by integration\n",
    "    fermi_integrated = aims_fields.calculate_fermi_energy(\n",
    "        kso_info_path=join(SCF_DIR(A), \"ks_orbital_info.out\"),\n",
    "        n_electrons=frame.get_atomic_numbers().sum(),\n",
    "        gaussian_width=LDOS[\"gaussian_width\"],\n",
    "        interpolation_truncation=0.5,\n",
    "    )\n",
    "    print(f\"Fermi energy for {A}: ChemPot: {calc_info['fermi_eV']}, VBM: {fermi_vbm}, integrated: {fermi_integrated}\")\n",
    "    calc_info[\"vbm_eV\"] = fermi_vbm\n",
    "    calc_info[\"fermi_integrated_eV\"] = fermi_integrated\n",
    "    utils.pickle_dict(join(SCF_DIR(A), \"calc_info.pickle\"), calc_info)\n",
    "    \n",
    "assert all(converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DOS with different alignments\n",
    "gaussian_width = 0.3\n",
    "e_grid = np.linspace(-15, 5, 1000)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 5), sharex=True, sharey=True)\n",
    "for A, frame in zip(STRUCTURE_ID, STRUCTURE):\n",
    "    calc_info = utils.unpickle_dict(join(SCF_DIR(A), \"calc_info.pickle\"))\n",
    "    kso_info_path = f\"{DATA_DIR}/{A}/ks_orbital_info.out\"\n",
    "    _, dos = aims_fields.calculate_dos(\n",
    "        kso_info_path, gaussian_width=gaussian_width, e_grid=e_grid\n",
    "    )\n",
    "\n",
    "    for ax, target_energy in zip(axes, [\"fermi_eV\", \"vbm_eV\", \"fermi_integrated_eV\"]):\n",
    "        ax.plot(\n",
    "            e_grid - calc_info[target_energy],\n",
    "            dos / frame.get_global_number_of_atoms(),\n",
    "            c=\"green\" if A == 6 else \"gray\",\n",
    "        )\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.set_ylabel(\"Total DOS\")\n",
    "ax.set_xlabel(\"Energy (eV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the aims.out files for RI calcs\n",
    "all_aims_outs = [join(RI_DIR(A), \"aims.out\") for A in STRUCTURE_ID]\n",
    "# for aims_out in all_aims_outs:\n",
    "#     if exists(aims_out):\n",
    "#         shutil.copy(aims_out, aims_out + \".copy.\" + utils.timestamp())\n",
    "#         os.remove(aims_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcs = {}\n",
    "for A, frame in zip(STRUCTURE_ID, STRUCTURE):\n",
    "    if not exists(RI_DIR(A)):  # make RI dir\n",
    "        os.makedirs(RI_DIR(A))\n",
    "    calcs[A] = {\"atoms\": frame}\n",
    "\n",
    "    # Get SCF calculation info and path to KS-orbital info\n",
    "    calc_info = utils.unpickle_dict(join(SCF_DIR(A), \"calc_info.pickle\"))\n",
    "    kso_info_path = join(SCF_DIR(A), \"ks_orbital_info.out\")\n",
    "\n",
    "    if FIELD_NAME == \"ildos\":  # define KSO weights and write to file\n",
    "\n",
    "        # Save LDOS settings\n",
    "        ldos_kwargs = {k: v for k, v in LDOS.items()}\n",
    "        ldos_kwargs[\"target_energy\"] = calc_info[ldos_kwargs[\"target_energy\"]]\n",
    "        utils.pickle_dict(join(RI_DIR(A), \"ldos_settings.pkl\"), ldos_kwargs)\n",
    "        print(f\"Structure {A}, target_energy: {ldos_kwargs['target_energy']}\")\n",
    "\n",
    "        # Write KS-orbital weight vector\n",
    "        kso_weights = aims_fields.get_kso_weight_vector_for_named_field(\n",
    "            field_name=FIELD_NAME, kso_info_path=kso_info_path, **ldos_kwargs\n",
    "        )\n",
    "        np.savetxt(join(RI_DIR(A), \"ks_orbital_weights.in\"), kso_weights)\n",
    "\n",
    "    elif FIELD_NAME == \"edensity\":\n",
    "        assert RI.get(\"ri_fit_total_density\") is not None\n",
    "\n",
    "    # Specify tailored cube edges\n",
    "    if RI.get(\"output\") == [\"cube ri_fit\"] and CUBE[\"slab\"] is True:\n",
    "        calcs[A][\"aims_kwargs\"] = aims_calc.get_aims_cube_edges_slab(\n",
    "            frame, CUBE.get(\"n_points\")\n",
    "        )\n",
    "\n",
    "    # Copy density matrix restart\n",
    "    for density_matrix in glob.glob(join(SCF_DIR(A), \"D*.csc\")):\n",
    "        shutil.copy(density_matrix, RI_DIR(A))\n",
    "\n",
    "\n",
    "# And the general settings for all calcs\n",
    "aims_kwargs = BASE_AIMS.copy()\n",
    "aims_kwargs.update(RI)\n",
    "\n",
    "# Run the RI fitting procedure in AIMS\n",
    "aims_calc.run_aims_array(\n",
    "    calcs=calcs,\n",
    "    aims_path=AIMS_PATH,\n",
    "    aims_kwargs=aims_kwargs,\n",
    "    sbatch_kwargs=SBATCH,\n",
    "    run_dir=RI_DIR,\n",
    "    load_modules=HPC[\"load_modules\"],\n",
    "    export_vars=HPC[\"export_vars\"],\n",
    "    run_command=\"srun\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until all AIMS calcs have finished\n",
    "all_finished = False\n",
    "while len(all_aims_outs) > 0:\n",
    "    for aims_out in all_aims_outs:\n",
    "        if exists(aims_out):\n",
    "            with open(aims_out, \"r\") as f:\n",
    "                # Basic check to see if AIMS calc has finished\n",
    "                if \"Leaving FHI-aims.\" in f.read():\n",
    "                    all_aims_outs.remove(aims_out)\n",
    "\n",
    "# Remove the density matrix restart files\n",
    "for A in STRUCTURE_ID:\n",
    "    for density_matrix in glob.glob(join(RI_DIR(A), \"D*.csc\")):\n",
    "        os.remove(density_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process -> metatensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aims_calc.process_aims_results_sbatch_array(\n",
    "    \"run-process-aims.sh\",\n",
    "    structure_idxs=STRUCTURE_ID,\n",
    "    run_dir=RI_DIR,\n",
    "    process_what=[\"coeffs\", \"ovlp\"],\n",
    "    **SBATCH_KWARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ri_ovlp.out from the RI dir if now processed into a TensorMap\n",
    "for A in STRUCTURE_ID:\n",
    "    if exists(join(PROCESSED_DIR(A), \"ri_ovlp.npz\")):\n",
    "        try:\n",
    "            os.remove(join(RI_DIR(A), \"ri_ovlp.out\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ri_ovlp.out already removed for structure {A}\")\n",
    "    else:\n",
    "        print(f\"Structure {A} not yet processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = []\n",
    "for A in STRUCTURE_ID:\n",
    "    mae = io.unpickle_dict(join(PROCESSED_DIR(A), 'calc_info.pickle'))['df_error_percent']['total']\n",
    "    print(f\"A = {A}, %MAE = {mae}\")\n",
    "    maes.append(mae)\n",
    "\n",
    "print(f\"\\nAverage %MAE = {np.mean(maes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a rebuild of the density from the target RI coefficients\n",
    "import shutil\n",
    "from settings import CUBE_KWARGS, LDOS_KWARGS, REBUILD_KWARGS, RI_KWARGS\n",
    "\n",
    "# And the general settings for all calcs\n",
    "aims_kwargs = BASE_AIMS_KWARGS.copy()\n",
    "aims_kwargs.update(REBUILD_KWARGS)\n",
    "\n",
    "# Define paths to the aims.out files for RI calcs\n",
    "all_aims_outs = [join(REBUILD_DIR(A), \"aims.out\") for A in STRUCTURE_ID]\n",
    "# for aims_out in all_aims_outs:\n",
    "#     if exists(aims_out):\n",
    "#         os.remove(aims_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcs = {\n",
    "#     A: {\"atoms\": structure, \"run_dir\": SCF_DIR(A)}\n",
    "#     for A, structure in zip(STRUCTURE_ID, STRUCTURE)\n",
    "# }\n",
    "calcs = {A: {\"atoms\": structure} for A, structure in zip(STRUCTURE_ID, STRUCTURE)}\n",
    "\n",
    "\n",
    "for A, frame in zip(STRUCTURE_ID, STRUCTURE):\n",
    "    if not exists(REBUILD_DIR(A)):\n",
    "        os.makedirs(REBUILD_DIR(A))\n",
    "\n",
    "    # Copy coefficients from RI dir to rebuild dir\n",
    "    shutil.copy(\n",
    "        join(RI_DIR(A), \"ri_coeffs.out\"),\n",
    "        join(REBUILD_DIR(A), \"ri_coeffs.in\"),\n",
    "    )\n",
    "\n",
    "    # Specify tailored cube edges\n",
    "    if RI_KWARGS.get(\"output\") == [\"cube ri_fit\"]:\n",
    "        if frame.info[\"category\"] == \"bulk\":\n",
    "            print(\"Bulk structure, not assigning cube slab edges\")\n",
    "        else:\n",
    "            if CUBE_KWARGS.get(\"slab\") is True:\n",
    "                calcs[A][\"aims_kwargs\"] = aims_calc.get_aims_cube_edges_slab(\n",
    "                    frame, CUBE_KWARGS.get(\"n_points\")\n",
    "                )\n",
    "            else:\n",
    "                calcs[A][\"aims_kwargs\"] = aims_calc.get_aims_cube_edges(\n",
    "                    frame, CUBE_KWARGS.get(\"n_points\")\n",
    "                )\n",
    "\n",
    "# Run the RI fitting procedure in AIMS\n",
    "aims_calc.run_aims_array(\n",
    "    calcs=calcs,\n",
    "    aims_path=AIMS_PATH,\n",
    "    aims_kwargs=aims_kwargs,\n",
    "    sbatch_kwargs=SBATCH_KWARGS,\n",
    "    run_dir=REBUILD_DIR,\n",
    "    load_modules=HPC_KWARGS[\"load_modules\"],\n",
    "    export_vars=HPC_KWARGS[\"export_vars\"],\n",
    "    run_command=\"srun\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until all AIMS calcs have finished\n",
    "all_finished = False\n",
    "while len(all_aims_outs) > 0:\n",
    "    for aims_out in all_aims_outs:\n",
    "        if exists(aims_out):\n",
    "            with open(aims_out, \"r\") as f:\n",
    "                # Basic check to see if AIMS calc has finished\n",
    "                if \"Leaving FHI-aims.\" in f.read():\n",
    "                    all_aims_outs.remove(aims_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
