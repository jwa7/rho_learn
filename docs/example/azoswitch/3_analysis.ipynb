{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Analyse Results and Visualize Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import rholearn.io\n",
    "from rholearn.analysis import compile_loss_data, average_losses\n",
    "from rholearn.plots import loss_vs_epoch, learning_curve, save_fig_mpltex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the various important directories\n",
    "root_dir = \"/Users/joe.abbott/Documents/phd/code/qml/rho_learn/docs/example/azoswitch\"\n",
    "data_dir = os.path.join(root_dir, \"data\", \"partitions\")\n",
    "run_dir = os.path.join(root_dir, \"simulations\", \"02_nonlinear\")\n",
    "\n",
    "# Create directories to save plots and visualizations\n",
    "plot_dir = os.path.join(run_dir, \"plots\")\n",
    "rholearn.io.check_or_create_dir(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of exercises and subsets to compile data for\n",
    "exercises = [0]\n",
    "subsets = [0]\n",
    "\n",
    "# Compile data\n",
    "train, test = compile_loss_data(run_dir, exercises, subsets)\n",
    "mean_train = average_losses(train)\n",
    "mean_test = average_losses(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-log plot of loss vs epoch\n",
    "fig, ax = loss_vs_epoch([mean_train, mean_test], sharey=False)\n",
    "\n",
    "# Format\n",
    "fig.tight_layout()\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(12)\n",
    "ax[0].set_ylabel(r\"train loss / Ha\")\n",
    "ax[1].set_ylabel(r\"test loss / Ha\")\n",
    "ax[1].legend(labels=[f\"subset {s}\" for s in np.sort(list(mean_test.keys()))])\n",
    "\n",
    "# Save\n",
    "save_fig_mpltex(fig, os.path.join(plot_dir, \"loss_vs_epoch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-log learning curve plot of loss vs training set size\n",
    "point = \"final\"  # take the final epoch loss, as opposed to \"best\" (i.e. lowest)\n",
    "fig, ax = learning_curve(\n",
    "    [mean_train, mean_test],\n",
    "    np.load(os.path.join(data_dir, \"subset_sizes_train.npy\"))[:1],\n",
    "    point=point,\n",
    ")\n",
    "\n",
    "# Format\n",
    "fig.tight_layout()\n",
    "ax.set_ylabel(point + r\" loss\")\n",
    "ax.legend(labels=[\"train\", \"test\"])\n",
    "\n",
    "# Save\n",
    "save_fig_mpltex(fig, os.path.join(plot_dir, \"learning_curve\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rholearn.io import unpickle_dict, load_tensormap_to_torch, load_torch_object\n",
    "\n",
    "# Load the settings dict from file\n",
    "settings = unpickle_dict(os.path.join(run_dir, \"settings.pickle\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the lambda-SOAP TensorMap for the validation structure and its QM (i.e. the\n",
    "target) electron density. Then, load the best model and make a prediction on the\n",
    "validation structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lambda-SOAP TensorMaps for the input and output validation structure\n",
    "in_val = load_tensormap_to_torch(\n",
    "    os.path.join(data_dir, \"in_val.npz\"), **settings[\"torch\"]\n",
    ")\n",
    "out_val = load_tensormap_to_torch(\n",
    "    os.path.join(data_dir, \"out_val.npz\"), **settings[\"torch\"]\n",
    ")\n",
    "\n",
    "# Load the best model from training. Upon inspection of the analysis plots above\n",
    "# the models trained on the largest training subset (3) have the lowest test\n",
    "# loss. For simplicity we'll just load the model from exercise 1, subset 3, but\n",
    "# in principle we could average the weights from multiple models.\n",
    "model = load_torch_object(\n",
    "    os.path.join(run_dir, \"exercise_0\", \"subset_0\", \"model.pt\"),\n",
    "    device=settings[\"torch\"][\"device\"],\n",
    "    torch_obj_str=\"model\",\n",
    ")\n",
    "\n",
    "# Make a prediction on the validation structure\n",
    "out_val_pred = model(in_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a parity plot of the target electron density coefficients against\n",
    "predicted, coloured by $\\lambda$ value $\\in [0, ..., 5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rholearn.plots import parity_plot\n",
    "\n",
    "fig, ax = parity_plot(out_val, out_val_pred, color_by=\"spherical_harmonics_l\")\n",
    "lim = [1e-6, 1e2]\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"target density coefficient value\")\n",
    "ax.set_ylabel(\"predicted density coefficient value\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also colour the plot according to the elemental species, where index 1\n",
    "indicates Hydrogen, 6 Carbon, 7 Nitrogen, 8 Oxygen, 16 Sulfur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = parity_plot(out_val, out_val_pred, color_by=\"species_center\")\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"target density coefficient value\")\n",
    "ax.set_ylabel(\"predicted density coefficient value\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Electron Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rholearn.utils import rename_tensor, delta_tensor\n",
    "from azoswitch_utils import drop_structure_label\n",
    "\n",
    "# Rename tensors to fit Q-Stack naming convention\n",
    "new_keys_names = [\"spherical_harmonics_l\", \"element\"]\n",
    "out_val = rename_tensor(drop_structure_label(out_val), keys_names=new_keys_names)\n",
    "out_val_pred = rename_tensor(drop_structure_label(out_val_pred), keys_names=new_keys_names)\n",
    "\n",
    "# Generate a delta electron density: QM - ML. This helps to visualize where the\n",
    "# ML model isn't working so well\n",
    "out_val_delta = delta_tensor(input=out_val_pred, target=out_val, absolute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qstack import compound\n",
    "\n",
    "# Build a molecule object using Q-Stack. The basis used in density fitting for\n",
    "# this particular dataset was ccpvqz jkfit\n",
    "molecule = compound.xyz_to_mol(\n",
    "    os.path.join(root_dir, \"data\", \"xyz\", val_xyz), basis=\"ccpvqz jkfit\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the density coefficients and convert them to cube file format using Q-Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qstack import equio\n",
    "from qstack.fields import density2file\n",
    "\n",
    "# Vectorize the coefficients from each of the TensorMaps\n",
    "vect_coeffs_target = equio.tensormap_to_vector(molecule, out_val)\n",
    "vect_coeffs_input = equio.tensormap_to_vector(molecule, out_val_pred)\n",
    "vect_coeffs_delta = equio.tensormap_to_vector(molecule, out_val_delta)\n",
    "\n",
    "# Define a number of grid points to represent the electon density on\n",
    "n = 90\n",
    "\n",
    "# Convert the basis function coefficients to a cube file\n",
    "for (coeffs, filename) in [\n",
    "    (vect_coeffs_target, \"out_val.cube\"),\n",
    "    (vect_coeffs_input, \"out_val_pred.cube\"),\n",
    "    (vect_coeffs_delta, \"out_val_delta.cube\"),\n",
    "]:\n",
    "    density2file.coeffs_to_cube(\n",
    "        molecule,\n",
    "        coeffs,\n",
    "        os.path.join(plot_dir, filename),\n",
    "        nx=n,\n",
    "        ny=n,\n",
    "        nz=n,\n",
    "        resolution=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "\n",
    "# Visualize the target density\n",
    "for filename in [\"out_val.cube\", \"out_val_pred.cube\", \"out_val_delta.cube\"]:\n",
    "    v = py3Dmol.view(os.path.join(plot_dir, filename))\n",
    "    v.setStyle({\"line\": {}})\n",
    "    v.addVolumetricData(\n",
    "        open(os.path.join(plot_dir, filename), \"r\").read(),\n",
    "        \"cube\",\n",
    "        {\"isoval\": 0.01, \"color\": \"blue\", \"opacity\": 0.8},\n",
    "    )\n",
    "    v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "576c71a426691bc103e620abf31b98f592c88b3903fdf6bf41ae71c4b8043fe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
