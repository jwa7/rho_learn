{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to Train Your Model (Live Demo #1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![M-stack ecosystem](../figures/m_stack_ecosystem.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Import M-stack packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Useful standard and scientific ML libraries\n",
    "import os\n",
    "import time\n",
    "import ase.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyscf\n",
    "import py3Dmol\n",
    "import torch\n",
    "\n",
    "# M-Stack packages\n",
    "import equistore   # storage format for atomistic ML\n",
    "import chemiscope  # interactive molecular visualization\n",
    "import rascaline   # generating structural representations\n",
    "import qstack      # quantum chemistry toolkit\n",
    "\n",
    "from equistore import Labels, TensorBlock, TensorMap\n",
    "from rascaline.utils import clebsch_gordan, old_clebsch_gordan, rotations\n",
    "\n",
    "# Torch-based density leaning\n",
    "from rholearn import io, data, features, loss, models, plots, training, utils\n",
    "from settings import rascal_hypers, data_settings, ml_settings, torch_settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Visualize and explore dataset: `chemiscope`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the water molecules from file\n",
    "frames = ase.io.read(os.path.join(data_settings[\"data_dir\"], \"water_monomers_1k.xyz\"), index=\":\")\n",
    "structure_idxs = np.arange(len(frames))\n",
    "\n",
    "# Display molecules with chemiscope\n",
    "# chemiscope.show(\n",
    "#     frames,\n",
    "#     properties={\n",
    "#         \"Mean O-H bond length, Angstrom\": [np.mean([f.get_distance(0, 1), f.get_distance(0, 2)]) for f in frames],\n",
    "#         \"H-O-H angle, degrees\": [f.get_angle(1, 0, 2) for f in frames],\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate $\\lambda$-SOAP descriptors\n",
    "\n",
    "### Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdas = np.arange(rascal_hypers[\"max_angular\"] + 1)\n",
    "\n",
    "# # Generate lambda-SOAP -- NEW VERSION\n",
    "# lsoap = clebsch_gordan.lambda_soap_vector(\n",
    "#     frames,\n",
    "#     rascal_hypers=rascal_hypers,\n",
    "#     lambdas=lambdas,\n",
    "#     only_keep_parity=+1,\n",
    "# )\n",
    "\n",
    "# # Generate lambda-SOAP -- OLD VERSION\n",
    "# # lsoap = old_clebsch_gordan.lambda_soap_vector(\n",
    "# #     frames,\n",
    "# #     rascal_hypers=rascal_hypers,\n",
    "# #     lambdas=lambdas,\n",
    "# #     only_keep_parity=+1,\n",
    "# # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the equivariance condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check equivariance\n",
    "\n",
    "# # Generate Wigner-D matrices, initialized with random angles\n",
    "# wig = rotations.WignerDReal(lmax=rascal_hypers[\"max_angular\"])\n",
    "# print(\"Random rotation angles (rad):\", wig.angles)\n",
    "\n",
    "# # Apply an O(3) transformation to each frame \n",
    "# frames_o3 = [rotations.transform_frame_o3(frame, wig.angles) for frame in frames]\n",
    "# assert not np.allclose(frames[0].positions, frames_o3[0].positions)\n",
    "\n",
    "# # Generate lambda-SOAP for the transformed frames\n",
    "# lsoap_o3 = clebsch_gordan.lambda_soap_vector(\n",
    "#     frames_o3,\n",
    "#     rascal_hypers=rascal_hypers,\n",
    "#     lambdas=lambdas,\n",
    "#     only_keep_parity=+1,\n",
    "# )\n",
    "\n",
    "# # Apply the O(3) transformation to the TensorMap\n",
    "# lsoap_transformed = wig.transform_tensormap_o3(lsoap)\n",
    "\n",
    "# # Check for equivariance!\n",
    "# assert equistore.equal_metadata(lsoap_transformed, lsoap_o3)\n",
    "# assert equistore.allclose(lsoap_transformed, lsoap_o3)\n",
    "# print(\"O(3) EQUIVARIANT!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dir for lambda-SOAP\n",
    "# lsoap_dir = os.path.join(data_settings[\"data_dir\"], \"lsoap\")\n",
    "# if not os.path.exists(lsoap_dir):\n",
    "#     os.mkdir(path=lsoap_dir)\n",
    "\n",
    "# # Split into separate TensorMaps for each structure\n",
    "# lsoap_split = equistore.split(\n",
    "#     lsoap,\n",
    "#     axis=\"samples\",\n",
    "#     grouped_labels=[\n",
    "#         Labels(names=\"structure\", values=np.array([A]).reshape(-1, 1))\n",
    "#         for A in range(n_frames)\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# # Save the lambda-SOAP features for each structure to a separate dir\n",
    "# for A, frame in enumerate(frames[:n_frames]):\n",
    "#     # Create dir\n",
    "#     struct_dir = os.path.join(lsoap_dir, f\"{A}\")\n",
    "#     if not os.path.exists(struct_dir):\n",
    "#         os.mkdir(path=struct_dir)\n",
    "#     # Save\n",
    "#     equistore.save(os.path.join(struct_dir, \"x.npz\"), lsoap_split[A])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split data and standardize invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the grouped indices for train/test(/val) splits\n",
    "# train_idxs, test_idxs, val_idxs = data.group_idxs(\n",
    "#     structure_idxs,\n",
    "#     n_groups=data_settings[\"n_groups\"],\n",
    "#     group_sizes=data_settings[\"group_sizes\"],\n",
    "#     shuffle=data_settings[\"shuffle\"],\n",
    "#     seed=data_settings[\"seed\"],\n",
    "# )\n",
    "\n",
    "# # Define new dir for storing standardized features\n",
    "# rho_std_dir = os.path.join(data_settings[\"data_dir\"], \"rho_std\")\n",
    "# if not os.path.exists(rho_std_dir):\n",
    "#     os.mkdir(rho_std_dir)\n",
    "\n",
    "# # Save the grouped indices\n",
    "# np.savez(\n",
    "#     os.path.join(rho_std_dir, \"idxs.npz\"),\n",
    "#     train=train_idxs,\n",
    "#     test=test_idxs,\n",
    "#     val=val_idxs,\n",
    "# )\n",
    "\n",
    "# # Load all the structures into a single TensorMap\n",
    "# c_list = [\n",
    "#     equistore.load(os.path.join(data_settings[\"data_dir\"], \"rho\", f\"{i}\", \"c.npz\"))\n",
    "#     for i in structure_idxs\n",
    "# ]\n",
    "# c_all = equistore.join(c_list, axis=\"samples\", remove_tensor_name=True)\n",
    "\n",
    "# # Split to get another TensroMap with only the training structures\n",
    "# c_train = equistore.slice(\n",
    "#     c_all,\n",
    "#     axis=\"samples\",\n",
    "#     labels=Labels(names=[\"structure\"], values=np.array([train_idxs]).reshape(-1, 1)),\n",
    "# )\n",
    "\n",
    "# # Get the invariant means and save\n",
    "# inv_means = features.get_invariant_means(c_train)\n",
    "# equistore.save(os.path.join(rho_std_dir, \"inv_means.npz\"), inv_means)\n",
    "\n",
    "# # Standardize the invariants of all strutcures\n",
    "# c_all_std = features.standardize_invariants(c_all, inv_means)\n",
    "\n",
    "# # Split into individual TensorMaps\n",
    "# c_all_split = equistore.split(\n",
    "#     c_all_std,\n",
    "#     axis=\"samples\",\n",
    "#     grouped_labels=[\n",
    "#         Labels(names=[\"structure\"], values=np.array([i]).reshape(-1, 1))\n",
    "#         for i in structure_idxs\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# # Save each structure in a separate directory\n",
    "# for A, c_std in enumerate(c_all_split):\n",
    "#     assert c_std.block(0).samples[\"structure\"][0] == A\n",
    "#     c_dir = os.path.join(rho_std_dir, f\"{A}\")\n",
    "#     if not os.path.exists(c_dir):\n",
    "#         os.mkdir(c_dir)\n",
    "#     equistore.save(os.path.join(c_dir, \"c.npz\"), c_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the torch dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import ml_settings\n",
    "\n",
    "# Build density dataset\n",
    "rho_data = data.RhoData(\n",
    "    structure_idxs,\n",
    "    input_dir=data_settings[\"input_dir\"],\n",
    "    output_dir=data_settings[\"output_dir\"],\n",
    "    overlap_dir=data_settings[\"overlap_dir\"],\n",
    "    out_invariant_means_path=data_settings[\"out_inv_means_path\"],\n",
    "    **torch_settings,\n",
    ")\n",
    "\n",
    "idxs = np.load(os.path.join(rho_data.output_dir, \"idxs.npz\"))\n",
    "\n",
    "# Build the train and test dataloaders\n",
    "n_train_subsets = data_settings.get(\"n_train_subsets\")\n",
    "if n_train_subsets is not None:\n",
    "    subset_sizes = data.get_log_subset_sizes(len(idxs[\"train\"]), n_train_subsets)\n",
    "    train_idxs = idxs[\"train\"][:subset_sizes[data_settings.get(\"i_train_subset\")]]\n",
    "else:\n",
    "    train_idxs = idxs[\"train\"]\n",
    "\n",
    "\n",
    "train_loader = data.RhoLoader(\n",
    "    rho_data, idxs=train_idxs, **ml_settings[\"loading\"]\n",
    ")\n",
    "test_loader = data.RhoLoader(\n",
    "    rho_data, idxs=idxs[\"test\"], **ml_settings[\"loading\"]\n",
    ")\n",
    "\n",
    "print(\"num train structures:\", len(train_loader.idxs))\n",
    "print(\"num test structures:\", len(test_loader.idxs))\n",
    "\n",
    "# Initialize objects or load from checkpoint\n",
    "restart_epoch = ml_settings[\"training\"][\"restart_epoch\"]\n",
    "if restart_epoch == 0:\n",
    "\n",
    "    # Initialize objects\n",
    "    objects = training.init_training_objects(\n",
    "        ml_settings,\n",
    "        input=rho_data[0][1],\n",
    "        output=rho_data[0][2],\n",
    "        out_invariant_means=rho_data.get_out_invariant_means(),\n",
    "    )\n",
    "else:\n",
    "    print(\"loading\")\n",
    "    # Load from checkpoint\n",
    "    objects = training.load_from_checkpoint(\n",
    "        path=os.path.join(ml_settings[\"run_dir\"], f\"checkpoint_{restart_epoch}.pt\"),\n",
    "        ml_settings=ml_settings,\n",
    "        input=rho_data[0][1],\n",
    "        output=rho_data[0][2],\n",
    "    )\n",
    "model, optimizer, rho_loss_fn, coeff_loss_fn, scheduler = objects\n",
    "\n",
    "# Reinitialize the scheduler\n",
    "# scheduler = ml_settings[\"scheduler\"][\"algorithm\"](\n",
    "#     optimizer=optimizer,\n",
    "#     **ml_settings[\"scheduler\"][\"args\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a run dir for saving results\n",
    "if not os.path.exists(ml_settings[\"run_dir\"]):\n",
    "    os.mkdir(ml_settings[\"run_dir\"])\n",
    "\n",
    "# Define a log file\n",
    "log_file = os.path.join(ml_settings[\"run_dir\"], \"log.txt\")\n",
    "io.log(log_file, \"# Model training\")\n",
    "io.log(log_file, \"# epoch train_loss test_loss lr time learning_on_rho\")\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(\n",
    "    ml_settings[\"training\"][\"restart_epoch\"] + 1, ml_settings[\"training\"][\"n_epochs\"] + 1\n",
    "):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Set some epoch-dependent settings\n",
    "    check_args = True if epoch == 0 else False\n",
    "    use_rho_loss = False\n",
    "    if ml_settings[\"training\"][\"learn_on_rho_after\"] is not None:\n",
    "        if epoch > ml_settings[\"training\"][\"learn_on_rho_after\"]:\n",
    "            use_rho_loss = True\n",
    "\n",
    "    # Iterate over training batches\n",
    "    for train_batch in train_loader:\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make a prediction and evaluate loss for each train structure in the batch\n",
    "        train_loss = 0\n",
    "        for a_train, x_train, c_train, s_train in zip(*train_batch):\n",
    "            # Make a prediction\n",
    "            c_train_pred = model(x_train, check_args=check_args)\n",
    "\n",
    "            # Evaluate the loss with either CoeffLoss or RhoLoss\n",
    "            if use_rho_loss:\n",
    "                train_loss += rho_loss_fn(\n",
    "                    c_train_pred, c_train, s_train, check_args=check_args\n",
    "                )\n",
    "            else:  # use CoeffLoss\n",
    "                train_loss += coeff_loss_fn(\n",
    "                    c_train_pred, c_train, check_args=check_args\n",
    "                )\n",
    "\n",
    "        # Calculate gradient and update parameters\n",
    "        train_loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store training loss\n",
    "        train_losses.append(train_loss.detach().numpy() / len(train_batch))\n",
    "\n",
    "    # Iterate over test batches: calculate the test loss *on the density*\n",
    "    for test_batch in test_loader:\n",
    "        # Make a prediction and evaluate loss for each test structure in the batch\n",
    "        test_loss = 0\n",
    "        for a_test, x_test, c_test, s_test in zip(*test_batch):\n",
    "            # Make a prediction and evaluate the los *on the density*\n",
    "            with torch.no_grad():\n",
    "                c_test_pred = model(x_test, check_args=check_args)\n",
    "                test_loss += rho_loss_fn(\n",
    "                    c_test_pred, c_test, s_test, check_args=check_args\n",
    "                )\n",
    "\n",
    "        test_losses.append(test_loss.detach().numpy() / len(test_batch))\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % ml_settings[\"training\"][\"save_interval\"] == 0:\n",
    "        training.save_checkpoint(\n",
    "            ml_settings[\"run_dir\"], epoch, model, optimizer, scheduler=scheduler\n",
    "        )\n",
    "\n",
    "    # Write log for the epoch\n",
    "    io.log(\n",
    "        log_file,\n",
    "        f\"{epoch} \"\n",
    "        f\"{np.round(train_losses[-1], 7)} \"\n",
    "        f\"{np.round(test_losses[-1], 7)} \"\n",
    "        f\"{np.round(scheduler.get_last_lr()[0], 7)} \"\n",
    "        f\"{np.round(time.time() - t0, 7)} \"\n",
    "        f\"{1 if use_rho_loss else 0} \",\n",
    "    )\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the results\n",
    "# results = np.loadtxt(os.path.join(ml_settings[\"run_dir\"], \"log.txt\"))\n",
    "\n",
    "# # Plot train and test loss versus epoch\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.loglog(results[:, 0], results[:, 1], label=\"train\")\n",
    "# ax.loglog(results[:, 0], results[:, 2], label=\"test\")\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"epoch\")\n",
    "# ax.set_ylabel(\"loss per batch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make a prediction on the validation structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the input and output validation TensorMaps\n",
    "# in_val = io.load_tensormap_to_torch(\n",
    "#     os.path.join(data_settings[\"data_dir\"], \"in_val.npz\"), **ml_settings[\"torch\"]\n",
    "# )\n",
    "# out_val = equistore.load(os.path.join(data_settings[\"data_dir\"], \"out_val.npz\"))\n",
    "\n",
    "# # Retrieve the unique structure\n",
    "# val_idx = equistore.unique_metadata(in_val, axis=\"samples\", names=\"structure\")[0][0]\n",
    "# val_frame = ase.io.read(\n",
    "#     os.path.join(data_settings[\"data_dir\"], \"water_monomers_1k.xyz\"), index=val_idx\n",
    "# )\n",
    "\n",
    "# # Build a pyscf Molecule object\n",
    "# val_mol = pyscf.gto.Mole().build(\n",
    "#     atom=[\n",
    "#         (i, j) for i, j in zip(val_frame.get_chemical_symbols(), val_frame.positions)\n",
    "#     ],\n",
    "#     basis=\"ccpvqz jkfit\",\n",
    "# )\n",
    "\n",
    "# # Predict the density\n",
    "# out_val_pred, coeffs = predictor.predict_density_from_mol(\n",
    "#     in_val,\n",
    "#     val_mol,\n",
    "#     model_path=os.path.join(ml_settings[\"run_dir\"], \"epoch_10\", \"model.pt\"),\n",
    "#     inv_means_path=os.path.join(data_settings[\"data_dir\"], \"inv_means.npz\"),\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parity plot: target vs predicted coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Calculate the MSE Error\n",
    "# with torch.no_grad():\n",
    "#     val_loss = loss.MSELoss(reduction=\"sum\")(\n",
    "#         utils.tensor_to_torch(out_val, **ml_settings[\"torch\"]), \n",
    "#         utils.tensor_to_torch(out_val_pred, **ml_settings[\"torch\"])\n",
    "#     ).detach().numpy()\n",
    "\n",
    "# # Plot the target vs predicted coefficients, standardized\n",
    "# fig, ax = plots.parity_plot(\n",
    "#     target=out_val,\n",
    "#     predicted=out_val_pred,\n",
    "#     color_by=\"spherical_harmonics_l\",\n",
    "# )\n",
    "# lim = [-0.05, 0.1]\n",
    "# ax.set_xlim(lim)\n",
    "# ax.set_ylim(lim)\n",
    "# ax.set_aspect(\"equal\")\n",
    "# ax.set_xlabel(\"target density coefficient\")\n",
    "# ax.set_ylabel(\"predicted density coefficient\")\n",
    "# ax.set_title(f\"Validation MSE Error: {round(val_loss * 1e6, 3)}\"r\" $\\times 10^{-6}$\")\n",
    "# ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Process densities with `Q-stack` and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Build a delta density TensorMap\n",
    "# out_val_delta = equistore.abs(equistore.subtract(out_val_pred, out_val))\n",
    "\n",
    "# # Vectorize the coefficients from each of the TensorMaps\n",
    "# new_key_names = [\"spherical_harmonics_l\", \"element\"]\n",
    "# vect_coeffs_target = qstack.equio.tensormap_to_vector(\n",
    "#     val_mol,\n",
    "#     utils.rename_tensor(\n",
    "#         utils.drop_metadata_name(out_val, \"samples\", \"structure\"),\n",
    "#         keys_names=new_key_names,\n",
    "#     ),\n",
    "# )\n",
    "# vect_coeffs_input = qstack.equio.tensormap_to_vector(\n",
    "#     val_mol,\n",
    "#     utils.rename_tensor(\n",
    "#         utils.drop_metadata_name(out_val_pred, \"samples\", \"structure\"),\n",
    "#         keys_names=new_key_names,\n",
    "#     ),\n",
    "# )\n",
    "# vect_coeffs_delta = qstack.equio.tensormap_to_vector(\n",
    "#     val_mol,\n",
    "#     utils.rename_tensor(\n",
    "#         utils.drop_metadata_name(out_val_delta, \"samples\", \"structure\"),\n",
    "#         keys_names=new_key_names,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# # Convert the basis function coefficients to a cube file\n",
    "# plot_dir = os.path.join(ml_settings[\"run_dir\"], \"plots\")\n",
    "# io.check_or_create_dir(plot_dir)\n",
    "# n = 60  # grid points per dimension\n",
    "# for (coeffs, filename) in [\n",
    "#     (vect_coeffs_target, \"out_val.cube\"),\n",
    "#     (vect_coeffs_input, \"out_val_pred.cube\"),\n",
    "#     (vect_coeffs_delta, \"out_val_delta.cube\"),\n",
    "# ]:\n",
    "#     qstack.fields.density2file.coeffs_to_cube(\n",
    "#         val_mol,\n",
    "#         coeffs,\n",
    "#         os.path.join(plot_dir, filename),\n",
    "#         nx=n,\n",
    "#         ny=n,\n",
    "#         nz=n,\n",
    "#         resolution=None,\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicted electron density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Visualize the predicted density\n",
    "# v = py3Dmol.view()\n",
    "# v.addModelsAsFrames(open(os.path.join(plot_dir, \"out_val_pred.cube\"), \"r\").read(), \"cube\")\n",
    "# v.setStyle({\"stick\": {}})\n",
    "# v.addVolumetricData(\n",
    "#     open(os.path.join(plot_dir, \"out_val_pred.cube\"), \"r\").read(),\n",
    "#     \"cube\",\n",
    "#     {\"isoval\": 0.05, \"color\": \"blue\", \"opacity\": 0.8},\n",
    "# )\n",
    "# v.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Delta electron density\" - i.e. the ML error (100x magnification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Visualize the delta density\n",
    "# v = py3Dmol.view()\n",
    "# v.addModelsAsFrames(open(os.path.join(plot_dir, \"out_val_delta.cube\"), \"r\").read(), \"cube\")\n",
    "# v.setStyle({\"stick\": {}})\n",
    "# v.addVolumetricData(\n",
    "#     open(os.path.join(plot_dir, \"out_val_delta.cube\"), \"r\").read(),\n",
    "#     \"cube\",\n",
    "#     {\"isoval\": 0.0005, \"color\": \"blue\", \"opacity\": 0.8},\n",
    "# )\n",
    "# v.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
