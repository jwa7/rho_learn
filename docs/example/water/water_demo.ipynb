{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - presentation figures\n",
    "# - %RMSE or MAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful standard and scientific ML libraries\n",
    "import os\n",
    "import ase.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyscf\n",
    "import py3Dmol\n",
    "import torch\n",
    "\n",
    "# M-Stack packages\n",
    "import equistore  # storage format for atomistic ML\n",
    "import chemiscope  # interactive molecular visualization\n",
    "import rascaline  # generating structural representations\n",
    "import qstack  # quantum chemistry toolkit\n",
    "\n",
    "import rholearn  # torch-based density leaning\n",
    "from rholearn import io, features, training, plots, predictor, pretraining, utils\n",
    "from settings import RASCAL_HYPERS, DATA_SETTINGS, ML_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20095ef366784af48eed24d75efae26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ChemiscopeWidget(value='{\"meta\": {\"name\": \" \"}, \"structures\": [{\"size\": 3, \"names\": [\"O\", \"H\", \"H\"], \"x\": [0.0â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the water molecules from file\n",
    "n_structures = 1000\n",
    "frames = ase.io.read(\n",
    "    os.path.join(DATA_SETTINGS[\"data_dir\"], \"water_monomers_1k.xyz\"), index=f\":{n_structures}\"\n",
    ")\n",
    "\n",
    "# Display molecules with chemiscope\n",
    "chemiscope.show(\n",
    "    frames,\n",
    "    properties={\n",
    "        \"Mean O-H bond length, Angstrom\": [np.mean([f.get_distance(0, 1), f.get_distance(0, 2)]) for f in frames],\n",
    "        \"H-O-H angle, degrees\": [f.get_angle(1, 0, 2) for f in frames],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Equivariant Structural Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute lambda-SOAP: uses rascaline to compute a SphericalExpansion (~ 25 secs)\n",
    "input = features.lambda_soap_vector(\n",
    "    frames, RASCAL_HYPERS, even_parity_only=True\n",
    ")\n",
    "# Drop the block for l=5, Hydrogen as this isn't included in the output electron density\n",
    "input = equistore.drop_blocks(input, keys=equistore.Labels(input.keys.names, np.array([[5, 1]])))\n",
    "\n",
    "# Save lambda-SOAP and hypers to file\n",
    "equistore.save(os.path.join(DATA_SETTINGS[\"data_dir\"], \"lambda_soap.npz\"), input)\n",
    "io.pickle_dict(os.path.join(DATA_SETTINGS[\"data_dir\"], \"rascal_hypers.pickle\"), RASCAL_HYPERS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equisolve.utils import split_data\n",
    "\n",
    "# Load lambda-SOAP and output electron density. Check metadata is consistent.\n",
    "input = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"lambda_soap.npz\"))\n",
    "output = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"e_densities.npz\"))\n",
    "assert equistore.equal_metadata(input, output, check=[\"samples\", \"components\"])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "[[in_train, in_test, in_val], [out_train, out_test, out_val]], grouped_labels = split_data(\n",
    "    [input, output],\n",
    "    axis=DATA_SETTINGS[\"axis\"],\n",
    "    names=DATA_SETTINGS[\"names\"],\n",
    "    n_groups=DATA_SETTINGS[\"n_groups\"],\n",
    "    group_sizes=DATA_SETTINGS[\"group_sizes\"],\n",
    "    seed=DATA_SETTINGS[\"seed\"],\n",
    ")\n",
    "tm_files = {\n",
    "    \"in_train.npz\": in_train,\n",
    "    \"in_test.npz\": in_test,\n",
    "    \"out_train.npz\": out_train,\n",
    "    \"out_test.npz\": out_test,\n",
    "    \"in_val.npz\": in_val,\n",
    "    \"out_val.npz\": out_val,\n",
    "}\n",
    "# Save the TensorMaps to file\n",
    "for name, tm in tm_files.items():\n",
    "    equistore.save(os.path.join(DATA_SETTINGS[\"data_dir\"], name), tm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Run Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulation run directory and save simulation\n",
    "io.check_or_create_dir(ML_SETTINGS[\"run_dir\"])\n",
    "io.pickle_dict(os.path.join(ML_SETTINGS[\"run_dir\"], \"train_settings.pickle\"), ML_SETTINGS)\n",
    "\n",
    "# IMPORTANT! - set the torch default dtype\n",
    "torch.set_default_dtype(ML_SETTINGS[\"torch\"][\"dtype\"])\n",
    "\n",
    "# Pre-construct the appropriate torch objects (i.e. models, loss fxns)\n",
    "pretraining.construct_torch_objects_in_train_dir(\n",
    "    DATA_SETTINGS[\"data_dir\"], ML_SETTINGS[\"run_dir\"], ML_SETTINGS, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training subdirectory\n",
    "train_rel_dir = \"\"\n",
    "train_run_dir = os.path.join(ML_SETTINGS[\"run_dir\"], train_rel_dir)\n",
    "\n",
    "# Load training data and torch objects\n",
    "data, model, loss_fn, optimizer = pretraining.load_training_objects(\n",
    "    train_rel_dir, DATA_SETTINGS[\"data_dir\"], ML_SETTINGS, ML_SETTINGS[\"training\"][\"restart_epoch\"]\n",
    ")\n",
    "\n",
    "# Unpack the data\n",
    "in_train, in_test, out_train, out_test = data\n",
    "\n",
    "# Execute model training\n",
    "print(f\"\\nTraining in subdirectory {train_run_dir}\")\n",
    "training.train(\n",
    "    in_train=in_train,\n",
    "    out_train=out_train,\n",
    "    in_test=in_test,\n",
    "    out_test=out_test,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=ML_SETTINGS[\"training\"][\"n_epochs\"],\n",
    "    save_interval=ML_SETTINGS[\"training\"][\"save_interval\"],\n",
    "    save_dir=train_run_dir,\n",
    "    restart=ML_SETTINGS[\"training\"][\"restart_epoch\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test losses\n",
    "losses = np.load(os.path.join(ML_SETTINGS[\"run_dir\"], \"losses.npz\"))\n",
    "\n",
    "# Plot losses\n",
    "fig, ax = plt.subplots(1, 1, sharey=True)\n",
    "ax.loglog(losses[\"train\"], label=\"linear, train\", color=\"blue\", linestyle=\"dashed\")\n",
    "ax.loglog(losses[\"test\"], label=\"linear, test\", color=\"blue\")\n",
    "ax.set_ylabel(\"MSE Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation structure and make a prediction\n",
    "# Load the input and output validation TensorMaps\n",
    "in_val = io.load_tensormap_to_torch(\n",
    "    os.path.join(DATA_SETTINGS[\"data_dir\"], \"in_val.npz\"), **ML_SETTINGS[\"torch\"]\n",
    ")\n",
    "out_val = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"out_val.npz\"))\n",
    "\n",
    "# Retrieve the unique structure\n",
    "val_idx = equistore.unique_metadata(in_val, axis=\"samples\", names=\"structure\")[0][0]\n",
    "val_frame = ase.io.read(\n",
    "    os.path.join(DATA_SETTINGS[\"data_dir\"], \"water_monomers_1k.xyz\"), index=val_idx\n",
    ")\n",
    "\n",
    "# Build a pyscf Molecule object\n",
    "val_mol = pyscf.gto.Mole().build(\n",
    "    atom=[\n",
    "        (i, j) for i, j in zip(val_frame.get_chemical_symbols(), val_frame.positions)\n",
    "    ],\n",
    "    basis=\"ccpvqz jkfit\",\n",
    ")\n",
    "\n",
    "# Predict the density\n",
    "out_val_pred, coeffs = predictor.predict_density_from_mol(\n",
    "    in_val,\n",
    "    val_mol,\n",
    "    model_path=os.path.join(ML_SETTINGS[\"run_dir\"], \"epoch_25\", \"model.pt\"),\n",
    "    inv_means_path=os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\"),\n",
    ")\n",
    "\n",
    "# Build a delta density TensorMap\n",
    "out_val_delta = equistore.subtract(out_val_pred, out_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plots.parity_plot(\n",
    "    target=utils.standardize_invariants(\n",
    "        out_val,\n",
    "        equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\")),\n",
    "    ),\n",
    "    predicted=utils.standardize_invariants(\n",
    "        out_val_pred,\n",
    "        equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\")),\n",
    "    ),\n",
    "    color_by=\"spherical_harmonics_l\",\n",
    ")\n",
    "lim = [-0.07, 0.07]\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"target density coefficient\")\n",
    "ax.set_ylabel(\"predicted density coefficient\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the coefficients from each of the TensorMaps\n",
    "new_key_names = [\"spherical_harmonics_l\", \"element\"]\n",
    "vect_coeffs_target = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "vect_coeffs_input = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val_pred, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "vect_coeffs_delta = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val_delta, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "pos_delta = [i if i >= 0 else 0 for i in vect_coeffs_delta]\n",
    "neg_delta = [i if i < 0 else 0 for i in vect_coeffs_delta]\n",
    "\n",
    "# Convert the basis function coefficients to a cube file\n",
    "plot_dir = os.path.join(ML_SETTINGS[\"run_dir\"], \"plots\")\n",
    "io.check_or_create_dir(plot_dir)\n",
    "n = 80  # grid points per dimension\n",
    "for (coeffs, filename) in [\n",
    "    (vect_coeffs_target, \"out_val.cube\"),\n",
    "    (vect_coeffs_input, \"out_val_pred.cube\"),\n",
    "    (vect_coeffs_delta, \"out_val_delta.cube\"),\n",
    "    (pos_delta, \"out_val_delta_pos.cube\"),\n",
    "    (neg_delta, \"out_val_delta_neg.cube\"),\n",
    "]:\n",
    "    qstack.fields.density2file.coeffs_to_cube(\n",
    "        val_mol,\n",
    "        coeffs,\n",
    "        os.path.join(plot_dir, filename),\n",
    "        nx=n,\n",
    "        ny=n,\n",
    "        nz=n,\n",
    "        resolution=None,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Electron Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target density\n",
    "v = py3Dmol.view(os.path.join(plot_dir, \"out_val_pred.cube\"))\n",
    "v.setStyle({\"stick\": {}})\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_pred.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.05, \"color\": \"blue\", \"opacity\": 0.8},\n",
    ")\n",
    "v.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the prediction error (100x magnification)\n",
    "\n",
    "### $\\Delta \\rho$ \"delta electron density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the delta density\n",
    "v = py3Dmol.view(os.path.join(plot_dir, \"out_val_delta.cube\"))\n",
    "v.setStyle({\"stick\": {}})\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_delta.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.0005, \"color\": \"blue\", \"opacity\": 0.8},\n",
    ")\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the delta density\n",
    "v = py3Dmol.view(os.path.join(plot_dir, \"out_val_delta.cube\"))\n",
    "v.setStyle({\"stick\": {}})\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_delta_pos.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.0005, \"color\": \"blue\", \"opacity\": 0.8},\n",
    ")\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_delta_neg.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.0005, \"color\": \"red\", \"opacity\": 0.8},\n",
    ")\n",
    "v.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "576c71a426691bc103e620abf31b98f592c88b3903fdf6bf41ae71c4b8043fe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
