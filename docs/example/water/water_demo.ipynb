{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to Train Your Model (Live Demo #1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Import M-stack packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful standard and scientific ML libraries\n",
    "import os\n",
    "import ase.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyscf\n",
    "import py3Dmol\n",
    "import torch\n",
    "\n",
    "# M-Stack packages\n",
    "import equistore   # storage format for atomistic ML\n",
    "import chemiscope  # interactive molecular visualization\n",
    "import rascaline   # generating structural representations\n",
    "import qstack      # quantum chemistry toolkit\n",
    "\n",
    "# Torch-based density leaning\n",
    "import rholearn\n",
    "from rholearn import io, features, loss, plots, predictor, pretraining, training, utils\n",
    "from settings import RASCAL_HYPERS, DATA_SETTINGS, ML_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Visualize and explore dataset: `chemiscope`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the water molecules from file\n",
    "frames = ase.io.read(os.path.join(DATA_SETTINGS[\"data_dir\"], \"water_monomers_1k.xyz\"), index=\":\")\n",
    "\n",
    "# Display molecules with chemiscope\n",
    "chemiscope.show(\n",
    "    frames,\n",
    "    properties={\n",
    "        \"Mean O-H bond length, Angstrom\": [np.mean([f.get_distance(0, 1), f.get_distance(0, 2)]) for f in frames],\n",
    "        \"H-O-H angle, degrees\": [f.get_angle(1, 0, 2) for f in frames],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![M-stack ecosystem](../figures/m_stack_ecosystem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Generate $\\lambda$-SOAP equivariant structural representation: `rascaline` + `equistore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute lambda-SOAP: uses rascaline to compute a SphericalExpansion (~ 25 secs)\n",
    "print(\"Computing lambda-SOAP representation...\")\n",
    "input = features.lambda_soap_vector(\n",
    "    frames, RASCAL_HYPERS, even_parity_only=True\n",
    ")\n",
    "# Drop the block for l=5, Hydrogen as this isn't included in the output electron density\n",
    "input = equistore.drop_blocks(input, keys=equistore.Labels(input.keys.names, np.array([[5, 1]])))\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "# Save lambda-SOAP and hypers to file\n",
    "equistore.save(os.path.join(DATA_SETTINGS[\"data_dir\"], \"lambda_soap.npz\"), input)\n",
    "io.pickle_dict(os.path.join(DATA_SETTINGS[\"data_dir\"], \"rascal_hypers.pickle\"), RASCAL_HYPERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect block for l = 4, oxygen\n",
    "input.block(spherical_harmonics_l=4, species_center=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Prepare data: `equistore`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from equisolve.utils import split_data\n",
    "\n",
    "# Load lambda-SOAP and output electron density. Check metadata is consistent.\n",
    "input = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"lambda_soap.npz\"))\n",
    "output = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"e_densities.npz\"))\n",
    "assert equistore.equal_metadata(input, output, check=[\"samples\", \"components\"])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "[[in_train, in_test, in_val], [out_train, out_test, out_val]], grouped_labels = split_data(\n",
    "    [input, output],\n",
    "    axis=DATA_SETTINGS[\"axis\"],\n",
    "    names=DATA_SETTINGS[\"names\"],\n",
    "    n_groups=DATA_SETTINGS[\"n_groups\"],\n",
    "    group_sizes=DATA_SETTINGS[\"group_sizes\"],\n",
    "    seed=DATA_SETTINGS[\"seed\"],\n",
    ")\n",
    "tm_files = {\n",
    "    \"in_train.npz\": in_train,\n",
    "    \"in_test.npz\": in_test,\n",
    "    \"out_train.npz\": out_train,\n",
    "    \"out_test.npz\": out_test,\n",
    "    \"in_val.npz\": in_val,\n",
    "    \"out_val.npz\": out_val,\n",
    "}\n",
    "# Save the TensorMaps to file\n",
    "for name, tm in tm_files.items():\n",
    "    equistore.save(os.path.join(DATA_SETTINGS[\"data_dir\"], name), tm)\n",
    "    \n",
    "print(f\"Data split sizes:\\n\\ntrain: {len(grouped_labels[0])}\\ntest: {len(grouped_labels[1])}\\nvalidation: {len(grouped_labels[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Run Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create simulation run directory and save simulation\n",
    "io.check_or_create_dir(ML_SETTINGS[\"run_dir\"])\n",
    "io.pickle_dict(os.path.join(ML_SETTINGS[\"run_dir\"], \"train_settings.pickle\"), ML_SETTINGS)\n",
    "\n",
    "# IMPORTANT! - set the torch default dtype\n",
    "torch.set_default_dtype(ML_SETTINGS[\"torch\"][\"dtype\"])\n",
    "\n",
    "# Pre-construct the appropriate torch objects (i.e. models, loss fxns)\n",
    "pretraining.construct_torch_objects_in_train_dir(\n",
    "    DATA_SETTINGS[\"data_dir\"], ML_SETTINGS[\"run_dir\"], ML_SETTINGS, \n",
    ")\n",
    "\n",
    "print(f\"Simulation directory prepared at:\\n\\n{ML_SETTINGS['run_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Train model: `PyTorch` + `equistore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training subdirectory\n",
    "train_rel_dir = \"\"\n",
    "train_run_dir = os.path.join(ML_SETTINGS[\"run_dir\"], train_rel_dir)\n",
    "\n",
    "# Load training data and torch objects\n",
    "data, model, loss_fn, optimizer = pretraining.load_training_objects(\n",
    "    train_rel_dir, DATA_SETTINGS[\"data_dir\"], ML_SETTINGS, ML_SETTINGS[\"training\"][\"restart_epoch\"]\n",
    ")\n",
    "\n",
    "# Unpack the data\n",
    "in_train, in_test, out_train, out_test = data\n",
    "\n",
    "# Execute model training\n",
    "print(f\"\\nTraining in subdirectory:\\n\\n{train_run_dir}\\n\")\n",
    "training.train(\n",
    "    in_train=in_train,\n",
    "    out_train=out_train,\n",
    "    in_test=in_test,\n",
    "    out_test=out_test,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=ML_SETTINGS[\"training\"][\"n_epochs\"],\n",
    "    save_interval=ML_SETTINGS[\"training\"][\"save_interval\"],\n",
    "    save_dir=train_run_dir,\n",
    "    restart=ML_SETTINGS[\"training\"][\"restart_epoch\"],\n",
    "    print_level=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss vs epoch plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the train and test losses\n",
    "losses = np.load(os.path.join(ML_SETTINGS[\"run_dir\"], \"losses.npz\"))\n",
    "\n",
    "# Plot losses\n",
    "fig, ax = plt.subplots(1, 1, sharey=True)\n",
    "ax.loglog(\n",
    "    losses[\"train\"], \n",
    "    label=\"linear, train\", \n",
    "    color=\"blue\", \n",
    "    linestyle=\"dashed\"\n",
    ")\n",
    "ax.loglog(\n",
    "    losses[\"test\"], \n",
    "    label=\"linear, test\", \n",
    "    color=\"blue\"\n",
    ")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"% MSE Loss\")\n",
    "ax.set_ylim(.83, .86)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make a prediction on a validation structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the input and output validation TensorMaps\n",
    "in_val = io.load_tensormap_to_torch(\n",
    "    os.path.join(DATA_SETTINGS[\"data_dir\"], \"in_val.npz\"), **ML_SETTINGS[\"torch\"]\n",
    ")\n",
    "out_val = equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"out_val.npz\"))\n",
    "\n",
    "# Retrieve the unique structure\n",
    "val_idx = equistore.unique_metadata(in_val, axis=\"samples\", names=\"structure\")[0][0]\n",
    "val_frame = ase.io.read(\n",
    "    os.path.join(DATA_SETTINGS[\"data_dir\"], \"water_monomers_1k.xyz\"), index=val_idx\n",
    ")\n",
    "\n",
    "# Build a pyscf Molecule object\n",
    "val_mol = pyscf.gto.Mole().build(\n",
    "    atom=[\n",
    "        (i, j) for i, j in zip(val_frame.get_chemical_symbols(), val_frame.positions)\n",
    "    ],\n",
    "    basis=\"ccpvqz jkfit\",\n",
    ")\n",
    "\n",
    "# Predict the density\n",
    "out_val_pred, coeffs = predictor.predict_density_from_mol(\n",
    "    in_val,\n",
    "    val_mol,\n",
    "    model_path=os.path.join(ML_SETTINGS[\"run_dir\"], \"epoch_10\", \"model.pt\"),\n",
    "    inv_means_path=os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\"),\n",
    ")\n",
    "\n",
    "# Build a delta density TensorMap\n",
    "out_val_delta = equistore.abs(equistore.subtract(out_val_pred, out_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parity plot: target vs predicted coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize the invariants\n",
    "out_val_std = utils.standardize_invariants(out_val, equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\")))\n",
    "out_val_pred_std = utils.standardize_invariants(out_val_pred, equistore.load(os.path.join(DATA_SETTINGS[\"data_dir\"], \"inv_means.npz\")))\n",
    "\n",
    "# Calculate the % MSE Error\n",
    "val_error = loss.naive_percent_loss(out_val, out_val_pred, backend='numpy')\n",
    "\n",
    "# Plot the target vs predicted coefficients, standardized\n",
    "fig, ax = plots.parity_plot(\n",
    "    target=out_val,\n",
    "    predicted=out_val_pred,\n",
    "    color_by=\"spherical_harmonics_l\",\n",
    ")\n",
    "lim = [-0.7, 3.5]\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"target density coefficient\")\n",
    "ax.set_ylabel(\"predicted density coefficient\")\n",
    "# ax.set_title(f\"Validation Error: {np.round(val_error, 3)} %\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Process densities with `Q-stack` and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the coefficients from each of the TensorMaps\n",
    "new_key_names = [\"spherical_harmonics_l\", \"element\"]\n",
    "vect_coeffs_target = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "vect_coeffs_input = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val_pred, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "vect_coeffs_delta = qstack.equio.tensormap_to_vector(\n",
    "    val_mol,\n",
    "    utils.rename_tensor(\n",
    "        utils.drop_metadata_name(out_val_delta, \"samples\", \"structure\"),\n",
    "        keys_names=new_key_names,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Convert the basis function coefficients to a cube file\n",
    "plot_dir = os.path.join(ML_SETTINGS[\"run_dir\"], \"plots\")\n",
    "io.check_or_create_dir(plot_dir)\n",
    "n = 60  # grid points per dimension\n",
    "for (coeffs, filename) in [\n",
    "    (vect_coeffs_target, \"out_val.cube\"),\n",
    "    (vect_coeffs_input, \"out_val_pred.cube\"),\n",
    "    (vect_coeffs_delta, \"out_val_delta.cube\"),\n",
    "]:\n",
    "    qstack.fields.density2file.coeffs_to_cube(\n",
    "        val_mol,\n",
    "        coeffs,\n",
    "        os.path.join(plot_dir, filename),\n",
    "        nx=n,\n",
    "        ny=n,\n",
    "        nz=n,\n",
    "        resolution=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicted electron density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the predicted density\n",
    "v = py3Dmol.view()\n",
    "v.addModelsAsFrames(open(os.path.join(plot_dir, \"out_val_pred.cube\"), \"r\").read(), \"cube\")\n",
    "v.setStyle({\"stick\": {}})\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_pred.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.05, \"color\": \"blue\", \"opacity\": 0.8},\n",
    ")\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Delta electron density\" - i.e. the ML error (10x magnification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the delta density\n",
    "v = py3Dmol.view()\n",
    "v.addModelsAsFrames(open(os.path.join(plot_dir, \"out_val_delta.cube\"), \"r\").read(), \"cube\")\n",
    "v.setStyle({\"stick\": {}})\n",
    "v.addVolumetricData(\n",
    "    open(os.path.join(plot_dir, \"out_val_delta.cube\"), \"r\").read(),\n",
    "    \"cube\",\n",
    "    {\"isoval\": 0.005, \"color\": \"blue\", \"opacity\": 0.8},\n",
    ")\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Poster session #14\n",
    "\n",
    "* Example training notebooks https://github.com/m-stack-org/rho_learn for:\n",
    "\n",
    "    * water\n",
    "    \n",
    "    * azoswitch molecules\n",
    "    \n",
    "    \n",
    "![azoswitch density](../figures/azoswitch_density.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rho] *",
   "language": "python",
   "name": "conda-env-rho-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "576c71a426691bc103e620abf31b98f592c88b3903fdf6bf41ae71c4b8043fe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
