"""
Generates features vectors for equivariant structural representations.
Currently implemented:
    - lambda-SOAP
"""
import os
import pickle
from typing import Sequence, Optional

import ase
import numpy as np

import equistore
from equistore import Labels, TensorMap

import rascaline
from rascaline.utils import clebsch_gordan

from rholearn import io, spherical, utils


def new_lambda_feature_vector(
    frames: Sequence[ase.Atoms],
    rascal_hypers: dict,
    lambdas: Sequence[int],
    lambda_cut: Optional[int] = None,
    selected_samples: Optional[Labels] = None,
    species_neighbors: Optional[Sequence[int]] = None,
    even_parity_only: bool = False,
    save_dir: Optional[str] = None,
) -> TensorMap:
    """
    A higher-level wrapper for the clebsch_gordan.n_body_iteration_single_center
    function of rascaline utils to generate and process a lambda-SOAP
    descriptor.
    """
    # Generate lambda-SOAP using rascaline.utils
    lsoap = clebsch_gordan.n_body_iteration_single_center(
        frames,
        rascal_hypers=rascal_hypers,
        nu_target=2,
        lambdas=lambdas,
        lambda_cut=lambda_cut,
        selected_samples=selected_samples,
        species_neighbors=species_neighbors,
    )

    # Drop the redundant key name "order_nu". This is by definition 2 for all
    # lambda-SOAP blocks.
    lsoap = utils.drop_key_name(lsoap, key_name="order_nu")
    utils.trim_memory()

    # Drop odd-parity blocks
    if even_parity_only:
        keys_to_drop = Labels(
            names=lsoap.keys.names,
            values=lsoap.keys.values[lsoap.keys.column("inversion_sigma") == -1],
        )
        lsoap = equistore.drop_blocks(lsoap, keys=keys_to_drop)

        # Drop the "inversion_sigma" key name
        lsoap = utils.drop_key_name(lsoap, key_name="inversion_sigma")
        utils.trim_memory()

    # Write hypers and features to file
    if save_dir is not None:
        with open(os.path.join(save_dir, f"rascal_hypers.pickle"), "wb") as handle:
            pickle.dump(rascal_hypers, handle, protocol=pickle.HIGHEST_PROTOCOL)
        equistore.save(os.path.join(save_dir, f"lsoap.npz"), lsoap)

    return lsoap


def lambda_soap_vector(
    frames: list,
    hypers: dict,
    lambda_cut: Optional[int] = None,
    selected_samples: Optional[Labels] = None,
    neighbor_species: Optional[Sequence[int]] = None,
    even_parity_only: bool = False,
    save_dir: Optional[str] = None,
    print_level: Optional[int] = 0,
) -> TensorMap:
    """
    Takes a list of frames of ASE loaded frames and a dict of Rascaline
    hyperparameters and generates a lambda-SOAP (i.e. nu=2) representation.

    Passing a subset of samples in `selected_samples` can be used to, for
    instance, only calculate the features for a subset of the strutcures passed
    in `frames`. For instance: `selected_samples = Labels(names=["structure"],
    values[4, 5, 6])` will only calculate the lambda-features for structures
    indexed by 4, 5, 6.

    :param frames: a list of structures generated by the ase.io function.
    :param hypers: a dict of hyperparameters used to calculate the atom density
        correlation calculated with rascaline SphericalExpansion
    :param lambda_cut: an int of the maximum lambda value to compute
        combinations for. If none, the 'max_angular' value in `hypers` will be
        used instead.
    :param selected_samples: a Labels object that defines which samples, as a
        subset of the total samples in `frames` (i.e. atomic environments or
        structures) to perform the calculation on.
    :param neighbor_species: a list of int that correspond to the atomic charges
        of all the neighbour species that you want to be in your properties (or
        features) dimension. This list may contain charges for atoms that don't
        appear in ``frames``, but are included anyway so that the one can
        enforce consistent properties dimension size with other lambda-feature
        vectors.
    :param even_parity_only: a bool that determines whether to only include the
        key/block pairs with even parity under rotation, i.e. sigma = +1.
        Defaults to false, where both parities are included.
    :param save_dir: a str of the absolute path to the directory where the
        TensorMap of the calculated lambda-SOAP representation and pickled
        ``hypers`` dict should be written. If none, the TensorMap will not be
        saved.

    :return: a TensorMap of the lambda-SOAP feature vector for the selected
        samples of the input frames.
    """
    # Create save directory
    if save_dir is not None:
        io.check_or_create_dir(save_dir)

    # Generate Rascaline hypers
    calculator = rascaline.SphericalExpansion(**hypers)
    if lambda_max is None:
        lambda_max = 2 * hypers["max_angular"]
    else:
        if lambda_max > 2 * hypers["max_angular"]:
            raise ValueError(
                "As this function generates 2-body features (nu=2), `lambda_max` must"
                f" be <= 2 x hypers['max_angular'] `hypers`. Received {lambda_max}."
            )
    # Pre-calculate ClebschGordan coefficients
    cg = spherical.ClebschGordanReal(l_max=lambda_max)

    # Generate descriptor via Spherical Expansion
    if print_level:
        print("Computing spherical expansion")
    acdc_nu1 = calculator.compute(frames, selected_samples=selected_samples)

    # nu=1 features
    if print_level:
        print("Standardizing keys")
    acdc_nu1 = spherical.acdc_standardize_keys(acdc_nu1)

    # Move "species_neighbor" sparse keys to properties with enforced atom
    # charges if ``neighbor_species`` is specified. This is required as the CG
    # iteration code currently does not handle neighbour species padding
    # automatically.
    keys_to_move = "species_neighbor"
    if neighbor_species is not None:
        keys_to_move = Labels(
            names=(keys_to_move,),
            values=np.array(neighbor_species).reshape(-1, 1),
        )
    if print_level:
        print("Moving keys to properties")
    acdc_nu1 = acdc_nu1.keys_to_properties(keys_to_move=keys_to_move)

    # Combined nu=1 features to generate nu=2 features. lambda-SOAP is defined
    # as just the nu=2 features.
    if print_level:
        print("Performing CG iteration to generate nu=2 features")
    acdc_nu2 = spherical.cg_increment(
        acdc_nu1,
        acdc_nu1,
        clebsch_gordan=cg,
        lcut=lambda_max,
        other_keys_match=["species_center"],
    )
    # Release acdc_nu1 from memory
    del acdc_nu1
    utils.trim_memory()

    # Clean the lambda-SOAP TensorMap. Drop the order_nu key name as this is by
    # definition 2 for all keys.
    if print_level:
        print("Dropping 'order_nu' from the key names")
    acdc_nu2 = utils.drop_key_name(acdc_nu2, key_name="order_nu")
    utils.trim_memory()

    if even_parity_only:
        # Drop all odd parity keys/blocks
        if print_level:
            print("Dropping blocks with odd parity")
        keys_to_drop = Labels(
            names=acdc_nu2.keys.names,
            values=acdc_nu2.keys.values[acdc_nu2.keys.column("inversion_sigma") == -1],
        )
        acdc_nu2 = equistore.drop_blocks(acdc_nu2, keys=keys_to_drop)
        utils.trim_memory()

        # Drop the inversion_sigma key name as this is now +1 for all blocks
        if print_level:
            print("Dropping 'inversion_sigma' from the key names")
        acdc_nu2 = utils.drop_key_name(acdc_nu2, key_name="inversion_sigma")
        utils.trim_memory()

    if save_dir is not None:  # Write hypers and features to file
        with open(
            os.path.join(save_dir, f"rascal_hypers_{calc}.pickle"), "wb"
        ) as handle:
            pickle.dump(hypers, handle, protocol=pickle.HIGHEST_PROTOCOL)
        equistore.save(os.path.join(save_dir, f"feat_vect_{calc}.npz"), acdc_nu2)

    return acdc_nu2


def lambda_feature_kernel(lsoap_vector: TensorMap) -> TensorMap:
    """
    Takes a lambda-feature vector (i.e. lambda-SOAP or lambda-LODE) as a
    TensorMap and takes the relevant inner products to form a lambda-feature
    kernel, returned as a TensorMap.
    """
    raise NotImplementedError


def get_invariant_means(tensor: TensorMap) -> TensorMap:
    """
    Calculates the mean of the invariant (l=0) blocks on the input `tensor`
    using the `equistore.mean_over_samples` function. Returns the result in a
    new TensorMap, whose number of blocks is equal to the number of invariant
    blocks in `tensor`. Assumes `tensor` is a numpy-based TensorMap.
    """
    # Define the keys of the covariant blocks
    keys_to_drop = Labels(
        names=tensor.keys.names,
        values=tensor.keys.values[tensor.keys.column("spherical_harmonics_l") != 0],
    )

    # Drop these blocks
    inv_tensor = equistore.drop_blocks(tensor, keys=keys_to_drop)

    # Find the mean over sample for the invariant blocks
    return equistore.mean_over_samples(inv_tensor, sample_names=inv_tensor.sample_names)


def standardize_invariants(
    tensor: TensorMap, invariant_means: TensorMap, reverse: bool = False
) -> TensorMap:
    """
    Standardizes the invariant (l=0) blocks on the input `tensor` by subtracting
    from each coefficient the mean of the coefficients belonging to that
    feature. Returns a new TensorMap.

    Must pass the TensorMap containing the means of the features,
    `invariant_means`. If `reverse` is true, the mean is instead added back to
    the coefficients of each feature. Assumes `tensor` and `invariant_means` are
    numpy-based TensorMaps.
    """
    new_keys = tensor.keys
    new_blocks = []
    # Iterate over the invariant keys
    for key in new_keys:
        if key in invariant_means.keys:  # standardize
            # Copy the block
            new_block = tensor[key].copy()
            # Manipulate values of copied block in place
            for p in range(len(new_block.properties)):
                if reverse:  # add the mean to the values
                    new_block.values[..., p] += invariant_means[key].values[..., p]
                else:  # subtract
                    new_block.values[..., p] -= invariant_means[key].values[..., p]
            new_blocks.append(new_block)
        else:  # Don't standardize
            new_blocks.append(tensor[key].copy())

    return TensorMap(new_keys, new_blocks)
